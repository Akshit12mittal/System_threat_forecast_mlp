# ğŸ›¡ï¸ System Threat Forecaster

## ğŸ† Scorecard

* **Final Model:** Tuned XGBoost
* **Final Accuracy:** 0.62510
* **Pass Threshold:** 0.55

## ğŸ“Œ Project Overview

This project was part of the **Machine Learning Practice (MLP)** course at **IIT Madras**. It was designed as a **full-fledged Kaggle-style competition** with over **1700 students** participating.

The task:
ğŸ‘‰ Predict whether a system is likely to get **infected by malware**, using **telemetry data** collected by antivirus software.

We were provided with three main files:

* **`train.csv`** â€“ containing labeled data (features + target)
* **`test.csv`** â€“ unlabeled data for which predictions had to be made
* **`submission.csv`** â€“ the required format for submitting predictions

---

## ğŸ—‚ï¸ Dataset Details

* **Training set:** \~100,000 rows Ã— 76 columns
* **Test set:** \~10,000 rows Ã— 75 columns
* **Target variable:** `target` (1 = infected, 0 = not infected)
* **Features:** System hardware, OS configurations, display settings, security measures, etc.

Challenges included:

* Missing values across multiple features
* Skewed numeric distributions (e.g., RAM, disk sizes)
* High-cardinality categorical variables
* Outliers and redundant columns

---

## ğŸ” Exploratory Data Analysis (EDA)

Before jumping into models, I **explored the dataset visually** to understand hidden patterns.

### 1. Target Distribution

* **Balanced classes**: Both infected and non-infected systems were reasonably represented.
* This meant accuracy was a valid metric (no major class imbalance).

### 2. Numeric Features

* Plotted **histograms** â†’ many features like RAM and disk size were **right-skewed**.
* **Boxplots** â†’ revealed strong outliers (e.g., unrealistic hardware specs).

ğŸ“– *Learning:* These distributions guided how I handled **missing values** (mean vs median) and **outlier treatment** (IQR clipping).

### 3. Categorical Features

* Used **bar plots** to visualize distributions of categorical columns.
* Found that some categories had only 1â€“2 unique values â†’ candidates for dropping.

ğŸ“– *Learning:* Low-cardinality features were encoded with one-hot, while higher ones needed label encoding.

### 4. Correlation Heatmap

* Plotted correlations between numeric features.
* Identified clusters (e.g., display settings correlated with resolution features).

ğŸ“– *Learning:* While no single feature was highly correlated with the target, groups of features together contributed predictive power.

---

## ğŸ› ï¸ Data Preprocessing

Steps applied systematically:

1. **Missing values:**

   * Numeric â†’ mean or median depending on skew
   * Categorical â†’ mode

2. **Feature reduction:**

   * Dropped constant columns
   * Removed duplicate rows

3. **Encoding:**

   * Binary categorical â†’ 0/1
   * Low-cardinality categorical â†’ one-hot encoded
   * Others â†’ label encoded

4. **Outlier handling:**

   * IQR-based clipping of extreme values

5. **Feature alignment:**

   * Ensured `train` and `test` sets had the same features after preprocessing

---

## ğŸ¤– Model Building

I tested multiple models to compare performance.

| Model               | Accuracy   |
| ------------------- | ---------- |
| Dummy Classifier    | 0.5061     |
| Random Forest       | 0.6171     |
| XGBoost (raw)       | 0.6217     |
| SGD Classifier      | 0.5206     |
| **XGBoost (tuned)** | **0.6251** |

### Dummy Classifier

* A simple baseline (majority class prediction).
* Accuracy = **0.5061** â†’ showed that any proper model must beat this.

### Random Forest ğŸŒ²

* Handled categorical + numerical mix well.
* Accuracy = **0.6171**.
* Feature importance revealed that **security settings, OS version, and RAM size** were more influential.

### XGBoost âš¡

* Outperformed Random Forest out-of-the-box: **0.6217**.
* Efficient with missing data and imbalanced distributions.

### SGD Classifier

* Struggled with convergence, poor accuracy (**0.5206**).

---

## ğŸ”§ Hyperparameter Tuning

Optimized **XGBoost** parameters:

* `n_estimators` (trees)
* `max_depth` (tree depth)
* `learning_rate` (step size)
* `subsample` and `colsample_bytree` (to avoid overfitting)

âœ¨ Accuracy improved to **0.6251**, comfortably above the pass threshold of **0.55**.

---

## ğŸ“Š Visual Insights

Some key visualizations included:

* **Target distribution plot** â†’ confirmed balance in classes.
* **Histograms of numeric features** â†’ revealed skewness and guided imputation.
* **Boxplots** â†’ highlighted outliers.
* **Heatmap of correlations** â†’ showed feature groups (though weak target correlation).
* **Feature importance plot (Random Forest / XGBoost)** â†’ showed that a few system security and configuration settings mattered most.

ğŸ“– *These visuals werenâ€™t just pretty â€” they guided decisions on preprocessing, encoding, and model selection.*

---

## ğŸ’¡ Learnings

* Always start with **EDA** to guide preprocessing and model choice.
* **Dummy baselines** help measure progress.
* **Tree-based models** (RF, XGBoost) shine with mixed data types.
* Handling **missing values, outliers, and categorical encoding** is as important as the model itself.
* **Hyperparameter tuning** is often the final boost for leaderboard performance.

---
